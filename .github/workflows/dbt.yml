name: "DBT Run"
on:
  push:
  schedule:
    - cron: "0 12 * * *" # every day at 12:00 pm

jobs:
  dbt:
    name: "Run dbt"
    permissions: write-all
    container: python:3.9
    runs-on: ubuntu-latest
    environment:
      name: dbt
      url: ${{ steps.deployment.outputs.page_url }}

    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    steps:
      - name: "Checkout"
        uses: actions/checkout@master
      - name: pip install
        run: pip install poetry
      - name: poetry install
        run: poetry install

      - name: run sqlfluff
        run: poetry run sqlfluff format models --dialect duckdb || true
      - name: dbt deps
        run: poetry run dbt deps

      - name: Download the dbt.duckdb from S3 and store MD5 hash as a variable
        id: download_and_get_md5
        run: |
          original_md5=$(poetry run python scripts/load_s3_files.py download)
          echo "::set-output name=md5::$original_md5"

      - name: dbt build
        run: poetry run dbt build --profiles-dir .

      - name: dbt source freshness
        run: poetry run dbt source freshness --profiles-dir .

      - uses: lassebenni/publish-to-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # GitHub sets this for you

      - name: Upload the dbt.duckdb to S3
        run: poetry run python scripts/load_s3_files.py upload "${{ steps.download_and_get_md5.outputs.md5 }}"

      - name: Setup DBT Docs to GH Pages
        uses: actions/configure-pages@v3
      - name: Generate docs
        run: poetry run dbt docs generate --profiles-dir .
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v1
        with:
          # Upload the target directory containing the docs
          path: "target"
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v1